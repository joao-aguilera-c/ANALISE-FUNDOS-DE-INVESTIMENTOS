{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0bb605",
   "metadata": {},
   "source": [
    "## Projeto de extração e análise de dados de Fundos de Investimentos Brasileiros\n",
    "\n",
    "#### Os fundos de investimento têm atraído cada vez mais pessoas que querem sair da poupança em busca de uma alternativa mais rentável ou diversificar os investimentos sem se preocupar em administrá-los em seus minímos detalhes. Porém a tarefa de escolhê-los está cada vez mais dificil. Por termos muitas opções é normal ficarmos perdidos, sem saber a melhor opção para alocarmos nossos investimentos.\n",
    "\n",
    "#### Com isso em mente preparei um estudo que visa clarificar este mercado para que possamos tomar as melhores descisões!\n",
    "\n",
    "#### O primeiro passo do nosso projeto consiste na extração e transformação dos dados de todos os FI brasileiros. Para isso utilizamos as seguintes fontes:\n",
    "\n",
    "\n",
    "- Portal Dados Abertos CVM:\n",
    "    No portal da CVM encontrei as cotas diárias de todos os fundos ativos no brasil desde 2005, com precisão diária.\n",
    "    Porém o único dado que temos de cada fundo é o seu CNPJ.\n",
    "    Fonte: http://dados.cvm.gov.br/dataset/fi-doc-inf_diario\n",
    "\n",
    "\n",
    "- financial.io:\n",
    "    Com o API da financial.io consegui mais informações sobre cada fundo, como nome, situação, classe de investimentos,\n",
    "    situação e gestor.\n",
    "    Fonte: https://financialdata.io/fundos\n",
    "\n",
    "\n",
    "- Debit.com.br:\n",
    "    - É importante também que tenhamos em mãos os benchmarks para analisarmos os fundos. Do site da Debit pude recolher \n",
    "    os dados de CDI (variação mensal) desde 1986 com precisão mensal.\n",
    "    Fonte: https://www.debit.com.br/tabelas/tabela-completa.php?indice=cdi\n",
    "    \n",
    "    - De lá extraí também os dados de IPCA(IBGE) (variação mensal) desde o ano de 1981, com precisão mensal.\n",
    "    Fonte: https://debit.com.br/tabelas/tabela-completa.php?indice=ipca\n",
    "    \n",
    "\n",
    "- Yahoo Finace:\n",
    "    Também utilizaremos como benchmark o indice bovespa (ibovespa) para FI que negociam ações. Para isso recolhemos dados\n",
    "    do site da Yahoo Finance, com precisão diária.\n",
    "    Fonte: https://br.financas.yahoo.com/quote/%5EBVSP/history/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcf6c2",
   "metadata": {},
   "source": [
    "### Portal Dados Abertos CVM\n",
    "\n",
    "O site da CVM disponibiliza diversas planilhas em csv, separadas por ano e mês. Para realizar de forma rápida sua extração, criamos o código de web scraping mostrado a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36062044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "URL = 'http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/'\n",
    "HIST_URL = 'HIST/'\n",
    "FILETYPE = '.csv'\n",
    "HIST_FILETYPE = '.zip'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    return bs(requests.get(url).text, 'html.parser')\n",
    "\n",
    "\n",
    "for link in get_soup(URL).findAll('a'):\n",
    "    file_link = link.get('href')\n",
    "    if FILETYPE in file_link:\n",
    "        print('Baixando', file_link)\n",
    "        with open(link.text, 'wb') as file:\n",
    "            response = requests.get(URL + file_link)\n",
    "            file.write(response.content)\n",
    "\n",
    "    if HIST_URL in file_link:\n",
    "        for hist_link in get_soup(URL + HIST_URL).findAll('a'):\n",
    "            file_link = hist_link.get('href')\n",
    "            if HIST_FILETYPE in file_link:\n",
    "                print('Baixando e descomprimindo', file_link)\n",
    "                remoteZip = urlopen(Request(URL + HIST_URL + file_link))\n",
    "                file_name = file_link\n",
    "                local_file = open(file_name, 'wb')\n",
    "                local_file.write(remoteZip.read())\n",
    "                local_file.close()\n",
    "\n",
    "                with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "                    zip_ref.extractall()\n",
    "\n",
    "                os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684a905",
   "metadata": {},
   "source": [
    "###### Exemplo da database da CVM\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ade28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-------------+-------------+------------+-----------------+-------------+------------+\n",
      "| TP_FUNDO   | CNPJ_FUNDO         | DT_COMPTC   |    VL_TOTAL |   VL_QUOTA |   VL_PATRIM_LIQ |   CAPTC_DIA |   RESG_DIA |\n",
      "|------------+--------------------+-------------+-------------+------------+-----------------+-------------+------------|\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-01  | 1.07311e+06 |    27.4711 |     1.0769e+06  |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-02  | 1.07326e+06 |    27.4725 |     1.07695e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-04  | 1.07341e+06 |    27.4742 |     1.07702e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-07  | 1.07355e+06 |    27.4756 |     1.07707e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-08  | 1.07339e+06 |    27.4771 |     1.07713e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-09  | 1.07086e+06 |    27.4786 |     1.07427e+06 |           0 |    2921.97 |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-10  | 1.07081e+06 |    27.4798 |     1.07431e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-11  | 1.07585e+06 |    27.4812 |     1.07437e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-14  | 1.07109e+06 |    27.4828 |     1.07443e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-15  | 1.07314e+06 |    27.484  |     1.07448e+06 |           0 |       0    |\n",
      "+------------+--------------------+-------------+-------------+------------+-----------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "cvm_df = pd.read_csv('inf_diario_fi_202106.csv', delimiter =';')\n",
    "cvm_df = cvm_df.iloc[:10 , :-1]\n",
    "\n",
    "\n",
    "print(tabulate(cvm_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b5de7",
   "metadata": {},
   "source": [
    "### financial.io\n",
    "\n",
    "Graças ao api da financial.io pude extrair mais informações de cada fundo, utilizando seu CNPJ (previamente extraido do portal de dados da CVM). Abaixo segue o código para a extração desses dados para uma única tabela, a 'unique_fi_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12244f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "def now():\n",
    "    now = datetime.datetime.now()\n",
    "    now_string = f'{now.hour}:{now.minute}:{now.second}'\n",
    "    return now_string\n",
    "\n",
    "\n",
    "# Gerando unique_fi.csv, uma tabela com todos os CNPJs únicos da database da CVM:\n",
    "files = [f for f in os.listdir('.') if os.path.isfile(f) and '.csv' in f]\n",
    "\n",
    "if 'unique_fi.csv' not in files:\n",
    "    files.reverse()\n",
    "    cnpj_df = pd.DataFrame(columns=['CNPJ_FUNDO'])\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, delimiter=';')\n",
    "        df.drop(df.columns.difference(['CNPJ_FUNDO']), 1, inplace=True)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        cnpj_df = pd.concat([cnpj_df, df])\n",
    "\n",
    "    cnpj_df.drop_duplicates(inplace=True)\n",
    "    cnpj_df.to_csv('unique_fi.csv', index=False)\n",
    "\n",
    "    \n",
    "# Coletando dados para cada fundo a partir de finantialdata.io:\n",
    "auth = json.dumps({'usuario': 'manutencao.contas@gmail.com', 'senha': '@eBy5xTZea9fu9n'})\n",
    "token = requests.post(\n",
    "    \"https://api.financialdata.io/token\",\n",
    "    data=auth,\n",
    "    headers={'content-type': 'application/json; charset=utf-8',\n",
    "             'data-type': 'text'}\n",
    ")\n",
    "\n",
    "\n",
    "# Criando o 'unique_fi_info.csv' pela primeira vez ou acrescentando dados caso ele já exista:\n",
    "if 'unique_fi_info.csv' not in files:\n",
    "    unique_fi_info_df = pd.DataFrame(columns=[\"CNPJ_FUNDO\", 'nome', 'nomeAbreviado', 'dataConstituicao',\n",
    "                                              'dataCancelamento', 'situacao', 'classe',\n",
    "                                              'investidorQualificado', 'textoTaxaPerformance',\n",
    "                                              'nomeAdministrador', 'nomeGestor'])\n",
    "    unique_fi_info_df.to_csv('unique_fi_info.csv', index=False)\n",
    "else:\n",
    "    unique_fi_info_df = pd.read_csv('unique_fi_info.csv')\n",
    "\n",
    "index = 0\n",
    "unique_fi_df = pd.read_csv('unique_fi.csv')\n",
    "unique_fi_df = unique_fi_df.values.tolist()\n",
    "\n",
    "\n",
    "while index < len(unique_fi_df):\n",
    "    cnpj = unique_fi_df[index][0]\n",
    "\n",
    "    if unique_fi_info_df.empty or index not in unique_fi_info_df.index\\\n",
    "            or unique_fi_info_df.at[index, \"CNPJ_FUNDO\"] != cnpj:\n",
    "        print(f'{now()} - Colecting data for {cnpj}')\n",
    "\n",
    "        cnpj_n = re.sub(\"[^0-9]\", \"\", cnpj)\n",
    "\n",
    "\n",
    "        try:\n",
    "            fi_info = requests.get(\n",
    "                f\"https://api.financialdata.io/fundos/{cnpj_n}\",\n",
    "                data=auth,\n",
    "                headers={'Authorization': 'Bearer ' + token.text}\n",
    "            )\n",
    "\n",
    "            if fi_info.status_code == 200:\n",
    "\n",
    "                fi_df = pd.json_normalize(fi_info.json())\n",
    "\n",
    "                fi_df.rename(columns={'cnpj': 'CNPJ_FUNDO'}, inplace=True)\n",
    "\n",
    "                fi_df.drop(fi_df.columns.difference([\"CNPJ_FUNDO\", 'nome', 'nomeAbreviado',\n",
    "                                                     'dataConstituicao', 'dataCancelamento',\n",
    "                                                     'situacao', 'classe', 'investidorQualificado',\n",
    "                                                     'textoTaxaPerformance', 'nomeAdministrador',\n",
    "                                                     'nomeGestor']),\n",
    "                           1,\n",
    "                           inplace=True)\n",
    "\n",
    "                unique_fi_info_df = unique_fi_info_df.append(fi_df, ignore_index=True)\n",
    "                pd.set_option('display.max_columns', None)\n",
    "\n",
    "                print(f'{now()} - Data successfully collected, FI name is {unique_fi_info_df.at[index, \"nome\"]}')\n",
    "            else:\n",
    "                print(f'{now()} - {cnpj} não encontrado')\n",
    "                index -=1\n",
    "\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f'{now()} - finantialdata.io not responding when asked for {cnpj}')\n",
    "            print(e)\n",
    "            index -= 1\n",
    "\n",
    "        # Salvando dados a cada 10 novos fundos recebidos:\n",
    "        if (index / 10).is_integer():\n",
    "            unique_fi_info_df.to_csv('unique_fi_info.csv', index=False)\n",
    "\n",
    "        # Requerindo um novo token a cada 1000 requests (e assim evitando problemas de autenticação):\n",
    "        if (index / 1000).is_integer():\n",
    "            token = requests.post(\n",
    "                \"https://api.financialdata.io/token\",\n",
    "                data=auth,\n",
    "                headers={'content-type': 'application/json; charset=utf-8',\n",
    "                         'data-type': 'text'}\n",
    "            )\n",
    "    index += 1\n",
    "\n",
    "# Salvando database pela última vez\n",
    "unique_fi_info_df.to_csv('unique_fi_info.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c0d1",
   "metadata": {},
   "source": [
    "###### Exemplo da database de informações dos fundos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f674f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------------------------------+-------------------------+---------------------+\n",
      "| CNPJ_FUNDO         | nomeAbreviado                               | situacao                | classe              |\n",
      "|--------------------+---------------------------------------------+-------------------------+---------------------|\n",
      "| 00.017.024/0001-53 | FI RF EXPONENCIAL                           | CANCELADA               | nan                 |\n",
      "| 00.068.305/0001-35 | FIC FI CAIXA EMPREENDER RF LP               | CANCELADA               | nan                 |\n",
      "| 00.071.477/0001-68 | BB RF CURTO PRAZO AUTOMÁTICO EMPRESA FIC FI | EM FUNCIONAMENTO NORMAL | Fundo de Renda Fixa |\n",
      "| 00.073.041/0001-08 | BB BESC RF PRÁTICO CP FI                    | CANCELADA               | nan                 |\n",
      "| 00.083.181/0001-67 | OPP I FIA BDR NÍVEL I IE                    | EM FUNCIONAMENTO NORMAL | Fundo de Ações      |\n",
      "| 00.089.915/0001-15 | AMARIL FRANKLIN FIC FIM                     | EM FUNCIONAMENTO NORMAL | Fundo Multimercado  |\n",
      "| 00.102.322/0001-41 | BOREAL AÇÕES III FIA IE                     | EM FUNCIONAMENTO NORMAL | Fundo de Ações      |\n",
      "| 00.180.995/0001-10 | SAFRA EXECUTIVE MAX RF FIC FI               | CANCELADA               | nan                 |\n",
      "| 00.185.259/0001-54 | OPPORTUNITY LOGICA II FIC FIA               | EM FUNCIONAMENTO NORMAL | Fundo de Ações      |\n",
      "| 00.194.256/0001-87 | BB EXTRAMERCADO FAE FI EM RF                | CANCELADA               | nan                 |\n",
      "+--------------------+---------------------------------------------+-------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "info_df = pd.read_csv('unique_fi_info.csv')\n",
    "\n",
    "info_df.drop(info_df.columns.difference(['CNPJ_FUNDO', 'nomeAbreviado', 'classe', 'situacao']),\n",
    "            1,\n",
    "            inplace=True\n",
    "    )\n",
    "\n",
    "info_df = info_df.iloc[:10]\n",
    "\n",
    "\n",
    "print(tabulate(info_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6994c4",
   "metadata": {},
   "source": [
    "### Debit.com.br\n",
    "\n",
    "A partir do site da debit extraí via web scraping a tabela com todas as variações do CDI desde 1986:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754697da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "\n",
    "URL = 'https://www.debit.com.br/tabelas/tabela-completa.php?indice=cdi'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    return bs(requests.get(url).text, 'html.parser')\n",
    "\n",
    "\n",
    "# cdi_df = pd.DataFrame(columns=['date', 'percentage_variation'])\n",
    "\n",
    "\n",
    "def get_cdi():\n",
    "    all_tds = get_soup(URL).findAll('td')\n",
    "    cdi_list = []\n",
    "    i = 0\n",
    "    for info in all_tds:\n",
    "        info_class = info.get('class')\n",
    "        if info_class == ['mdl-data-table__cell--non-numeric']:\n",
    "            date = info.text\n",
    "            variation = all_tds[i+1].text\n",
    "\n",
    "            cdi_list.append([date, variation.replace(',', '.')])\n",
    "            pass\n",
    "\n",
    "        i += 1\n",
    "    cdi_df = pd.DataFrame(data=cdi_list,columns=['date', 'percentage_variation'])\n",
    "    cdi_df.to_csv('cdi.csv', index=False)\n",
    "\n",
    "\n",
    "def covert_dates():\n",
    "    cdi_df = pd.read_csv('cdi.csv')\n",
    "    i = 0\n",
    "    while i < len(cdi_df):\n",
    "        date = datetime.strptime(cdi_df.at[i, 'date'], '%m/%Y')\n",
    "        date = datetime.strftime(date, \"%Y-%m-%d\")\n",
    "        cdi_df.at[i, 'date'] = date\n",
    "        i += 1\n",
    "\n",
    "    cdi_df.to_csv('cdi.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "get_cdi()\n",
    "covert_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b0328",
   "metadata": {},
   "source": [
    "###### Exemplo da database de CDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6def9b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------+\n",
      "| date       |   percentage_variation |\n",
      "|------------+------------------------|\n",
      "| 2020-09-01 |                   0.16 |\n",
      "| 2020-10-01 |                   0.16 |\n",
      "| 2020-11-01 |                   0.15 |\n",
      "| 2020-12-01 |                   0.16 |\n",
      "| 2021-01-01 |                   0.15 |\n",
      "| 2021-02-01 |                   0.13 |\n",
      "| 2021-03-01 |                   0.2  |\n",
      "| 2021-04-01 |                   0.21 |\n",
      "| 2021-05-01 |                   0.27 |\n",
      "| 2021-06-01 |                   0.31 |\n",
      "+------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "cdi_df = pd.read_csv('cdi.csv', delimiter =',')\n",
    "cdi_df = cdi_df.tail(10)\n",
    "\n",
    "\n",
    "print(tabulate(cdi_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ed15b",
   "metadata": {},
   "source": [
    "###### Do mesmo site retirei as informações relativas ao IPCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "\n",
    "URL = 'https://debit.com.br/tabelas/tabela-completa.php?indice=ipca'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    return bs(requests.get(url).text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ipca():\n",
    "    all_tds = get_soup(URL).findAll('td')\n",
    "    ipca_list = []\n",
    "    i = 0\n",
    "    for info in all_tds:\n",
    "        info_class = info.get('class')\n",
    "        if info_class == ['mdl-data-table__cell--non-numeric']:\n",
    "            date = info.text\n",
    "            variation = all_tds[i+1].text\n",
    "\n",
    "            ipca_list.append([date, variation.replace(',', '.')])\n",
    "            pass\n",
    "\n",
    "        i += 1\n",
    "    ipca_df = pd.DataFrame(data=ipca_list,columns=['date', 'ipca_percentage_variation'])\n",
    "    ipca_df.to_csv('ipca.csv', index=False)\n",
    "\n",
    "\n",
    "def covert_dates():\n",
    "    ipca_df = pd.read_csv('ipca.csv')\n",
    "    i = 0\n",
    "    while i < len(ipca_df):\n",
    "        date = datetime.strptime(ipca_df.at[i, 'date'], '%m/%Y')\n",
    "        date = datetime.strftime(date, \"%Y-%m-%d\")\n",
    "        ipca_df.at[i, 'date'] = date\n",
    "        i += 1\n",
    "\n",
    "    ipca_df.to_csv('ipca.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "get_ipca()\n",
    "covert_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c1720",
   "metadata": {},
   "source": [
    "###### Exemplo da database do IPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8d3a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------------+\n",
      "| date       |   ipca_percentage_variation |\n",
      "|------------+-----------------------------|\n",
      "| 2020-09-01 |                        0.64 |\n",
      "| 2020-10-01 |                        0.86 |\n",
      "| 2020-11-01 |                        0.89 |\n",
      "| 2020-12-01 |                        1.35 |\n",
      "| 2021-01-01 |                        0.25 |\n",
      "| 2021-02-01 |                        0.86 |\n",
      "| 2021-03-01 |                        0.93 |\n",
      "| 2021-04-01 |                        0.31 |\n",
      "| 2021-05-01 |                        0.83 |\n",
      "| 2021-06-01 |                        0.53 |\n",
      "+------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "ipca_df = pd.read_csv('ipca.csv', delimiter =',')\n",
    "ipca_df = ipca_df.tail(10)\n",
    "\n",
    "\n",
    "print(tabulate(ipca_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceca7a8",
   "metadata": {},
   "source": [
    "### Yahoo Finace:\n",
    "\n",
    "No site de finanças do yahoo, conseguimos baixar com apenas um clique os dados diários do IBOV.\n",
    "\n",
    "###### Exemplo da database do IBOV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa465440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------+--------+---------+-------------+------------+\n",
      "| Date       |   Open |   High |    Low |   Close |   Adj Close |     Volume |\n",
      "|------------+--------+--------+--------+---------+-------------+------------|\n",
      "| 2021-07-19 | 125958 | 125958 | 123317 |  124395 |      124395 | 9.2102e+06 |\n",
      "| 2021-07-20 | 124395 | 125631 | 123631 |  125401 |      125401 | 7.6275e+06 |\n",
      "| 2021-07-21 | 125404 | 126112 | 125247 |  125929 |      125929 | 7.1489e+06 |\n",
      "| 2021-07-22 | 125930 | 126428 | 125416 |  126147 |      126147 | 6.4804e+06 |\n",
      "| 2021-07-23 | 126140 | 126204 | 124422 |  125053 |      125053 | 6.0518e+06 |\n",
      "| 2021-07-26 | 125058 | 126214 | 125006 |  126004 |      126004 | 6.3255e+06 |\n",
      "| 2021-07-27 | 126004 | 126026 | 123670 |  124612 |      124612 | 7.3138e+06 |\n",
      "| 2021-07-28 | 124615 | 126712 | 124542 |  126286 |      126286 | 9.0382e+06 |\n",
      "| 2021-07-29 | 126285 | 126476 | 124917 |  125675 |      125675 | 7.4884e+06 |\n",
      "| 2021-07-30 | 125672 | 125673 | 121748 |  121801 |      121801 | 9.3992e+06 |\n",
      "+------------+--------+--------+--------+---------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "ibov_df = pd.read_csv('ibov.csv', delimiter =',')\n",
    "ibov_df = ibov_df.tail(10)\n",
    "\n",
    "\n",
    "print(tabulate(ibov_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c772c1",
   "metadata": {},
   "source": [
    "### ETL concluída, quais os proximos passos?\n",
    "\n",
    "###### Agora que finalizamos a primeira etapa do projeto, chega a hora de analizar a fundo o cenário dos fundos de investimento brasileiros. Algumas perguntas ficam no ar:\n",
    "\n",
    "- Qual a duração média dos fundos que não estão mais ativos? Entender mais sobre o ciclo de vida dos fundos brasileiros\n",
    "  é essencial para melhor definirmos essa classe de ivestimento;\n",
    "\n",
    "- Quantos dos fundos ativos performam acima do seu benchmark? É realmente lucrativo apostar nos fundos ao invés de apenas\n",
    "  investir no IBOV ou CDI?\n",
    "\n",
    "- Quais fundos melhor performaram ao longo dos anos, e por quanto tempo? Em qualquer cenário existem os vencedores e os não\n",
    "  tão habilidosos. Saber quais os melhores gestores e fundos nos ajudará a alocarmos melhor nosso suado dinheiro!\n",
    "\n",
    "###### Essas e outras perguntas serão respondidas na proxima sessão: Análise dos FI Brasileiros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
