{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0bb605",
   "metadata": {},
   "source": [
    "## Projeto de extração e análise de dados de Fundos de Investimentos Brasileiros\n",
    "\n",
    "#### Os fundos de investimento têm atraído cada vez mais as pessoas que querem sair da poupança em busca de uma alternativa mais rentável ou diversificar os investimentos sem se preocupar em administrá-los de perto. Porém a tarefa de escolhê-los está cada vez mais dificil. Por termos muitas opções muitas vezes ficamos perdidos, sem saber a melhor opção para alocarmos nossos investimentos.\n",
    "\n",
    "#### Com isso em mente preparamos um estudo que visa clarificar este mercado para que possamos fazer a melhor escolha!\n",
    "\n",
    "#### O primeiro passo do nosso projeto consiste na extração e transformação dos dados de todos os FI brasileiros. Para isso utilizamos as seguintes fontes:\n",
    "\n",
    "\n",
    "- Portal Dados Abertos CVM:\n",
    "    No portal da CVM encontramos as cotas diárias de todos os fundos ativos no brasil desde 2005, com precisão diária.\n",
    "    Porém o único dado que temos de cada fundo é o seu CNPJ.\n",
    "    Fonte: http://dados.cvm.gov.br/dataset/fi-doc-inf_diario\n",
    "\n",
    "\n",
    "- financial.io:\n",
    "    Com o API da financial.io conseguimos mais informações sobre cada fundo como nome, situação, classe de investimentos,\n",
    "    situação e gestor.\n",
    "    Fonte: https://financialdata.io/fundos\n",
    "\n",
    "\n",
    "- Debit.com.br:\n",
    "    É importante também que tenhamos em mãos os benchmarks para analisarmos os fundos. Do site da Debit podemos recolher \n",
    "    os dados de CDI desde 1986 com precisão mensal.\n",
    "    Fonte: https://www.debit.com.br/tabelas/tabela-completa.php?indice=cdi\n",
    "    \n",
    "\n",
    "- Yahoo Finace:\n",
    "    Também utilizaremos como benchmark o indice bovespa (ibovespa) para FI que negociam ações. Para isso recolhemos dados\n",
    "    do site da Yahoo Finance, com precisão diária.\n",
    "    Fonte: https://br.financas.yahoo.com/quote/%5EBVSP/history/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcf6c2",
   "metadata": {},
   "source": [
    "### Portal Dados Abertos CVM\n",
    "\n",
    "No portal da CVM temos diversas planilhas em csv, separadas por ano e mês. Para realizar de forma rápida sua extração, criamos o código de web scraping mostrado a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36062044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "URL = 'http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/'\n",
    "HIST_URL = 'HIST/'\n",
    "FILETYPE = '.csv'\n",
    "HIST_FILETYPE = '.zip'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    return bs(requests.get(url).text, 'html.parser')\n",
    "\n",
    "\n",
    "for link in get_soup(URL).findAll('a'):\n",
    "    file_link = link.get('href')\n",
    "    if FILETYPE in file_link:\n",
    "        print('Baixando', file_link)\n",
    "        with open(link.text, 'wb') as file:\n",
    "            response = requests.get(URL + file_link)\n",
    "            file.write(response.content)\n",
    "\n",
    "    if HIST_URL in file_link:\n",
    "        for hist_link in get_soup(URL + HIST_URL).findAll('a'):\n",
    "            file_link = hist_link.get('href')\n",
    "            if HIST_FILETYPE in file_link:\n",
    "                print('Baixando e descomprimindo', file_link)\n",
    "                remoteZip = urlopen(Request(URL + HIST_URL + file_link))\n",
    "                file_name = file_link\n",
    "                local_file = open(file_name, 'wb')\n",
    "                local_file.write(remoteZip.read())\n",
    "                local_file.close()\n",
    "\n",
    "                with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "                    zip_ref.extractall()\n",
    "\n",
    "                os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684a905",
   "metadata": {},
   "source": [
    "###### Exemplo da database da CVM\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ade28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-------------+-------------+------------+-----------------+-------------+------------+\n",
      "| TP_FUNDO   | CNPJ_FUNDO         | DT_COMPTC   |    VL_TOTAL |   VL_QUOTA |   VL_PATRIM_LIQ |   CAPTC_DIA |   RESG_DIA |\n",
      "|------------+--------------------+-------------+-------------+------------+-----------------+-------------+------------|\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-01  | 1.07311e+06 |    27.4711 |     1.0769e+06  |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-02  | 1.07326e+06 |    27.4725 |     1.07695e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-04  | 1.07341e+06 |    27.4742 |     1.07702e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-07  | 1.07355e+06 |    27.4756 |     1.07707e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-08  | 1.07339e+06 |    27.4771 |     1.07713e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-09  | 1.07086e+06 |    27.4786 |     1.07427e+06 |           0 |    2921.97 |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-10  | 1.07081e+06 |    27.4798 |     1.07431e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-11  | 1.07585e+06 |    27.4812 |     1.07437e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-14  | 1.07109e+06 |    27.4828 |     1.07443e+06 |           0 |       0    |\n",
      "| FI         | 00.017.024/0001-53 | 2021-06-15  | 1.07314e+06 |    27.484  |     1.07448e+06 |           0 |       0    |\n",
      "+------------+--------------------+-------------+-------------+------------+-----------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "cvm_df = pd.read_csv('inf_diario_fi_202106.csv', delimiter =';')\n",
    "cvm_df = cvm_df.iloc[:10 , :-1]\n",
    "\n",
    "\n",
    "print(tabulate(cvm_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b5de7",
   "metadata": {},
   "source": [
    "### financial.io\n",
    "\n",
    "Graças ao api da financial.io podemos extrair mais informações de cada fundo, utilizando seu CNPJ (previamente extraido do portal de dados da CVM). Abaixo segue o código para a extração desses dados para uma única tabela, a 'unique_fi_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12244f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "def now():\n",
    "    now = datetime.datetime.now()\n",
    "    now_string = f'{now.hour}:{now.minute}:{now.second}'\n",
    "    return now_string\n",
    "\n",
    "\n",
    "# Gerando unique_fi.csv, uma tabela com todos os CNPJs únicos da database da CVM:\n",
    "files = [f for f in os.listdir('.') if os.path.isfile(f) and '.csv' in f]\n",
    "\n",
    "if 'unique_fi.csv' not in files:\n",
    "    files.reverse()\n",
    "    cnpj_df = pd.DataFrame(columns=['CNPJ_FUNDO'])\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, delimiter=';')\n",
    "        df.drop(df.columns.difference(['CNPJ_FUNDO']), 1, inplace=True)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        cnpj_df = pd.concat([cnpj_df, df])\n",
    "\n",
    "    cnpj_df.drop_duplicates(inplace=True)\n",
    "    cnpj_df.to_csv('unique_fi.csv', index=False)\n",
    "\n",
    "    \n",
    "# Coletando dados para cada fundo a partir de finantialdata.io:\n",
    "auth = json.dumps({'usuario': 'manutencao.contas@gmail.com', 'senha': '@eBy5xTZea9fu9n'})\n",
    "token = requests.post(\n",
    "    \"https://api.financialdata.io/token\",\n",
    "    data=auth,\n",
    "    headers={'content-type': 'application/json; charset=utf-8',\n",
    "             'data-type': 'text'}\n",
    ")\n",
    "\n",
    "\n",
    "# Criando o 'unique_fi_info.csv' pela primeira vez ou acrescentando dados caso ele já exista:\n",
    "if 'unique_fi_info.csv' not in files:\n",
    "    unique_fi_info_df = pd.DataFrame(columns=[\"CNPJ_FUNDO\", 'nome', 'nomeAbreviado', 'dataConstituicao',\n",
    "                                              'dataCancelamento', 'situacao', 'classe',\n",
    "                                              'investidorQualificado', 'textoTaxaPerformance',\n",
    "                                              'nomeAdministrador', 'nomeGestor'])\n",
    "    unique_fi_info_df.to_csv('unique_fi_info.csv', index=False)\n",
    "else:\n",
    "    unique_fi_info_df = pd.read_csv('unique_fi_info.csv')\n",
    "\n",
    "index = 0\n",
    "unique_fi_df = pd.read_csv('unique_fi.csv')\n",
    "unique_fi_df = unique_fi_df.values.tolist()\n",
    "\n",
    "\n",
    "while index < len(unique_fi_df):\n",
    "    cnpj = unique_fi_df[index][0]\n",
    "\n",
    "    if unique_fi_info_df.empty or index not in unique_fi_info_df.index\\\n",
    "            or unique_fi_info_df.at[index, \"CNPJ_FUNDO\"] != cnpj:\n",
    "        print(f'{now()} - Colecting data for {cnpj}')\n",
    "\n",
    "        cnpj_n = re.sub(\"[^0-9]\", \"\", cnpj)\n",
    "\n",
    "\n",
    "        try:\n",
    "            fi_info = requests.get(\n",
    "                f\"https://api.financialdata.io/fundos/{cnpj_n}\",\n",
    "                data=auth,\n",
    "                headers={'Authorization': 'Bearer ' + token.text}\n",
    "            )\n",
    "\n",
    "            if fi_info.status_code == 200:\n",
    "\n",
    "                fi_df = pd.json_normalize(fi_info.json())\n",
    "\n",
    "                fi_df.rename(columns={'cnpj': 'CNPJ_FUNDO'}, inplace=True)\n",
    "\n",
    "                fi_df.drop(fi_df.columns.difference([\"CNPJ_FUNDO\", 'nome', 'nomeAbreviado',\n",
    "                                                     'dataConstituicao', 'dataCancelamento',\n",
    "                                                     'situacao', 'classe', 'investidorQualificado',\n",
    "                                                     'textoTaxaPerformance', 'nomeAdministrador',\n",
    "                                                     'nomeGestor']),\n",
    "                           1,\n",
    "                           inplace=True)\n",
    "\n",
    "                unique_fi_info_df = unique_fi_info_df.append(fi_df, ignore_index=True)\n",
    "                pd.set_option('display.max_columns', None)\n",
    "\n",
    "                print(f'{now()} - Data successfully collected, FI name is {unique_fi_info_df.at[index, \"nome\"]}')\n",
    "            else:\n",
    "                print(f'{now()} - {cnpj} não encontrado')\n",
    "                index -=1\n",
    "\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f'{now()} - finantialdata.io not responding when asked for {cnpj}')\n",
    "            print(e)\n",
    "            index -= 1\n",
    "\n",
    "        # Salvando dados a cada 10 novos fundos recebidos:\n",
    "        if (index / 10).is_integer():\n",
    "            unique_fi_info_df.to_csv('unique_fi_info.csv', index=False)\n",
    "\n",
    "        # Requerindo um novo token a cada 1000 requests (e assim evitando problemas de autenticação):\n",
    "        if (index / 1000).is_integer():\n",
    "            token = requests.post(\n",
    "                \"https://api.financialdata.io/token\",\n",
    "                data=auth,\n",
    "                headers={'content-type': 'application/json; charset=utf-8',\n",
    "                         'data-type': 'text'}\n",
    "            )\n",
    "    index += 1\n",
    "\n",
    "# Salvando database pela última vez\n",
    "unique_fi_info_df.to_csv('unique_fi_info.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c0d1",
   "metadata": {},
   "source": [
    "###### Exemplo da database de informações dos fundos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f674f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------------------------------+-------------------------+---------------------+\n",
      "| CNPJ_FUNDO         | nomeAbreviado                               | situacao                | classe              |\n",
      "|--------------------+---------------------------------------------+-------------------------+---------------------|\n",
      "| 00.017.024/0001-53 | FI RF EXPONENCIAL                           | CANCELADA               | nan                 |\n",
      "| 00.068.305/0001-35 | FIC FI CAIXA EMPREENDER RF LP               | CANCELADA               | nan                 |\n",
      "| 00.071.477/0001-68 | BB RF CURTO PRAZO AUTOMÁTICO EMPRESA FIC FI | EM FUNCIONAMENTO NORMAL | Fundo de Renda Fixa |\n",
      "| 00.073.041/0001-08 | BB BESC RF PRÁTICO CP FI                    | CANCELADA               | nan                 |\n",
      "| 00.083.181/0001-67 | OPP I FIA BDR NÍVEL I IE                    | EM FUNCIONAMENTO NORMAL | Fundo de Ações      |\n",
      "| 00.089.915/0001-15 | AMARIL FRANKLIN FIC FIM                     | EM FUNCIONAMENTO NORMAL | Fundo Multimercado  |\n",
      "| 00.102.322/0001-41 | BOREAL AÇÕES III FIA IE                     | EM FUNCIONAMENTO NORMAL | Fundo de Ações      |\n",
      "| 00.180.995/0001-10 | SAFRA EXECUTIVE MAX RF FIC FI               | CANCELADA               | nan                 |\n",
      "| 00.185.259/0001-54 | OPPORTUNITY LOGICA II FIC FIA               | EM FUNCIONAMENTO NORMAL | Fundo de Ações      |\n",
      "| 00.194.256/0001-87 | BB EXTRAMERCADO FAE FI EM RF                | CANCELADA               | nan                 |\n",
      "+--------------------+---------------------------------------------+-------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "cvm_df = pd.read_csv('unique_fi_info.csv')\n",
    "\n",
    "cvm_df.drop(cvm_df.columns.difference(['CNPJ_FUNDO', 'nomeAbreviado', 'classe', 'situacao']),\n",
    "            1,\n",
    "            inplace=True\n",
    "    )\n",
    "\n",
    "cvm_df = cvm_df.iloc[:10]\n",
    "\n",
    "\n",
    "print(tabulate(cvm_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6994c4",
   "metadata": {},
   "source": [
    "### Debit.com.br\n",
    "\n",
    "Do site da debit, podemos a partir de webscraping criar uma tabela com todas as variações do CDI desde 1986:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754697da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "\n",
    "URL = 'https://www.debit.com.br/tabelas/tabela-completa.php?indice=cdi'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    return bs(requests.get(url).text, 'html.parser')\n",
    "\n",
    "\n",
    "# cdi_df = pd.DataFrame(columns=['date', 'percentage_variation'])\n",
    "\n",
    "\n",
    "def get_cdi():\n",
    "    all_tds = get_soup(URL).findAll('td')\n",
    "    cdi_list = []\n",
    "    i = 0\n",
    "    for info in all_tds:\n",
    "        info_class = info.get('class')\n",
    "        if info_class == ['mdl-data-table__cell--non-numeric']:\n",
    "            date = info.text\n",
    "            variation = all_tds[i+1].text\n",
    "\n",
    "            cdi_list.append([date, variation.replace(',', '.')])\n",
    "            pass\n",
    "\n",
    "        i += 1\n",
    "    cdi_df = pd.DataFrame(data=cdi_list,columns=['date', 'percentage_variation'])\n",
    "    cdi_df.to_csv('cdi.csv', index=False)\n",
    "\n",
    "\n",
    "def covert_dates():\n",
    "    cdi_df = pd.read_csv('cdi.csv')\n",
    "    i = 0\n",
    "    while i < len(cdi_df):\n",
    "        date = datetime.strptime(cdi_df.at[i, 'date'], '%m/%Y')\n",
    "        date = datetime.strftime(date, \"%Y-%m-%d\")\n",
    "        cdi_df.at[i, 'date'] = date\n",
    "        i += 1\n",
    "\n",
    "    cdi_df.to_csv('cdi.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "get_cdi()\n",
    "covert_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b0328",
   "metadata": {},
   "source": [
    "###### Exemplo da database de CDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6def9b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------+\n",
      "| date       |   percentage_variation |\n",
      "|------------+------------------------|\n",
      "| 1986-07-01 |                   1.84 |\n",
      "| 1986-08-01 |                   2.3  |\n",
      "| 1986-09-01 |                   2.71 |\n",
      "| 1986-10-01 |                   2.87 |\n",
      "| 1986-11-01 |                   5.15 |\n",
      "| 1986-12-01 |                   9.71 |\n",
      "| 1987-01-01 |                  13.67 |\n",
      "| 1987-02-01 |                  21.93 |\n",
      "| 1987-03-01 |                  13.8  |\n",
      "| 1987-04-01 |                  15.5  |\n",
      "+------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "cvm_df = pd.read_csv('cdi.csv', delimiter =',')\n",
    "cvm_df = cvm_df.iloc[:10 ]\n",
    "\n",
    "\n",
    "print(tabulate(cvm_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceca7a8",
   "metadata": {},
   "source": [
    "### Yahoo Finace:\n",
    "\n",
    "No site de finanças do yahoo, conseguimos baixar com apenas um clique os dados diários do IBOV.\n",
    "\n",
    "###### Exemplo da database do IBOV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa465440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------+-------+---------+-------------+----------+\n",
      "| Date       |   Open |   High |   Low |   Close |   Adj Close |   Volume |\n",
      "|------------+--------+--------+-------+---------+-------------+----------|\n",
      "| 1993-04-27 |   24.8 |   25.4 |  24.5 |    24.5 |        24.5 |        0 |\n",
      "| 1993-04-28 |   24.5 |   24.6 |  23.7 |    24.3 |        24.3 |        0 |\n",
      "| 1993-04-29 |   24.3 |   24.8 |  23.7 |    23.7 |        23.7 |        0 |\n",
      "| 1993-04-30 |   23.7 |   24.2 |  23.7 |    24.1 |        24.1 |        0 |\n",
      "| 1993-05-03 |   24.1 |   24.4 |  23.8 |    24.1 |        24.1 |        0 |\n",
      "| 1993-05-04 |   24.1 |   25   |  24.1 |    24.9 |        24.9 |        0 |\n",
      "| 1993-05-05 |   24.9 |   24.9 |  24.3 |    24.6 |        24.6 |        0 |\n",
      "| 1993-05-06 |   24.6 |   25.7 |  24.6 |    25.6 |        25.6 |        0 |\n",
      "| 1993-05-07 |   25.6 |   26.1 |  25.5 |    25.8 |        25.8 |        0 |\n",
      "| 1993-05-10 |   25.8 |   25.8 |  25.1 |    25.2 |        25.2 |        0 |\n",
      "+------------+--------+--------+-------+---------+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "cvm_df = pd.read_csv('ibov.csv', delimiter =',')\n",
    "cvm_df = cvm_df.iloc[:10 ]\n",
    "\n",
    "\n",
    "print(tabulate(cvm_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c772c1",
   "metadata": {},
   "source": [
    "### ETL concluída, quais os proximos passos?\n",
    "\n",
    "###### Agora que finalizamos a primeira etapa do projeto, chega a hora de analizar a fundo o cenário dos fundos de investimento brasileiros. Algumas perguntas ficam no ar:\n",
    "\n",
    "- Qual a duração média dos fundos que não estão mais ativos? Entender mais sobre o ciclo de vida dos fundos brasileiros\n",
    "  é essencial para melhor definirmos essa classe de ivestimento;\n",
    "\n",
    "- Quantos dos fundos ativos performam acima do seu benchmark? É realmente lucrativo apostar nos fundos ao invés de apenas\n",
    "  investir no IBOV ou CDI?\n",
    "\n",
    "- Quais fundos melhor performaram ao longo dos anos, e por quanto tempo? Em qualquer cenário existem os vencedores e os não\n",
    "  tão habilidosos. Saber quais os melhores gestores e fundos nos ajudará a alocarmos melhor nosso suado dinheiro!\n",
    "\n",
    "###### Essas e outras perguntas serão respondidas na proxima sessão: Análise dos FI Brasileiros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
